{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f63357-b847-4d01-b041-c46617c640cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"high_blood_pressure.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16cbf03-ca42-47ae-8d63-daffb34f0932",
   "metadata": {},
   "source": [
    "목표: 고혈압 환자 치료 전후의 혈압\n",
    "\n",
    "효과가 있는지 대응 표본 t-검정을 진행하시외.\n",
    "\n",
    "귀무가설(H0):  \r\n",
    "  >= 0\r\n",
    "대립가설(H1): μ\r\n",
    "  \r\n",
    "μ\r\n",
    "  = (치료 후 혈압 - 치료 전 혈압)의 평균\r\n",
    "유의\n",
    "수준0.05\r\n",
    "μ\r\n",
    " 의 표본평균은?(소수 둘째자리까지 반올림)\r\n",
    "검정통계량 값은?(소수 넷째자리까지 반올림)\r\n",
    "p-값은?(소수 넷째자리까지 반올림)\r\n",
    "가설검정의 결과는\n",
    "\n",
    "대응 표본 T검정: ttest_rel? (유의수준 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bd77e4-e393-483b-b339-fb8fb7ae3bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>bp_pre</th>\n",
       "      <th>bp_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p001</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>149</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p003</td>\n",
       "      <td>Male</td>\n",
       "      <td>70</td>\n",
       "      <td>176</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p004</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>169</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p005</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>160</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id     sex  age  bp_pre  bp_post\n",
       "0  p001    Male   33     149      129\n",
       "1  p002    Male   39     168      168\n",
       "2  p003    Male   70     176      155\n",
       "3  p004  Female   41     169      178\n",
       "4  p005    Male   48     160      126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20b7dd5f-873a-4c7b-bf69-72bd376ff140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0002163948827545 0.0016434474228511028\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#1\n",
    "df['diff'] = (df['bp_pre']-df['bp_post']) \n",
    "round(df['diff'].mean(),2)\n",
    "\n",
    "#2\n",
    "st, pv = stats.ttest_rel(df['bp_post'], df['bp_pre'], alternative = 'less') # 전후차이일때 사용\n",
    "print(st, pv)\n",
    "# st는 통계결과, p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f03a3-8d86-40b0-84ec-c2e2ba3eb523",
   "metadata": {},
   "source": [
    "어떤 특정 약물을 복용한 사람들의 평균 체온이 복용하지 않은 사람들의 평균 체온과 유의미하게 다른지 검정해보려고한다.\n",
    "\n",
    "검정 통계량, p-value, 검정 결과를 출력\n",
    "\n",
    "독립표본 T검정: ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b5b9641-3662-47bc-8aca-98e5e5005166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# 데이터 수집\n",
    "group1 = [36.8, 36.7, 37.1, 36.9, 37.2, 36.8, 36.9, 37.1, 36.7, 37.1]\n",
    "group2 = [36.5, 36.6, 36.3, 36.6, 36.9, 36.7, 36.7, 36.8, 36.5, 36.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "824287d6-33b1-421f-9bf6-c53588d5342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7964208654863336 0.001321891476703691\n"
     ]
    }
   ],
   "source": [
    "sv, pv = stats.ttest_ind(group1, group2)\n",
    "print(sv, pv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9709040-4c38-49d1-8b83-a133e619d5e1",
   "metadata": {},
   "source": [
    "문제: 다음은 22명의 학생들이 국어시험에서 받은 점수이다. 학생들의 평균이 75보다 크다고 할 수 있는가?¶\r\n",
    "귀무가설(H0): 모평균은 mu와 같다. (μ = mu), 학생들의 평균은 75이다\r\n",
    "대립가설(H1): 모평균은 mu보다 크다. (μ > mu), 학생들의 평균은 75보다 크다\r\n",
    "가정:\r\n",
    "\r\n",
    "모집단은 정규분포를 따른다.\r\n",
    "표본의 크기가 충분히 크다.\r\n",
    "검정통계량, p-value, 검정결과\n",
    "\n",
    "단일표본 T검정: ttest_1samp를 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d03e887-34ac-4d87-a3cc-5d48a03ccfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.765879233231226 0.04597614747709146\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "scores = [75, 80, 68, 72, 77, 82, 81, 79, 70, 74, 76, 78, 81, 73, 81, 78, 75, 72, 74, 79, 78, 79]\n",
    "\n",
    "criteria = 75\n",
    "cv, pv = ttest_1samp(scores, criteria, alternative = \"greater\")\n",
    "\n",
    "print(cv, pv)\n",
    "# help(ttest_1samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f1277-e926-486c-846c-6a9ad3193e59",
   "metadata": {},
   "source": [
    "세 가지 다른 교육 방법(A, B, C)을 사용하여 수험생들의 시험 성적을 개선시키는 효과를 평가하고자 한다. 30명의 학생들을 무작위로 세 그룹으로 배정하여 교육을 실시하였고, 시험을 보고 성적을 측정하였습니다. 다음은 각 그룹의 학생들의 성적 데이터입니다.\r\n",
    "귀무가설(H0): 세 그룹(A, B, C) 간의 평균 성적 차이가 없다.\r\n",
    "대립가설(H1 또는 Ha): 세 그룹(A, B, C) 간의 평균 성적 차이가 있다.\r\n",
    "일원배치법을 수행하여 그룹 간의 평균 성적 차이가 있는지 검정하세요\r\n",
    "f값 (소수 둘째자리)\r\n",
    "p값 (소수 여섯째자리)\r\n",
    "검정결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38ccd78d-a037-4ab9-9b45-c06e91e7f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function f_oneway in module scipy.stats._stats_py:\n",
      "\n",
      "f_oneway(*samples, axis=0, nan_policy='propagate', keepdims=False)\n",
      "    Perform one-way ANOVA.\n",
      "    \n",
      "    The one-way ANOVA tests the null hypothesis that two or more groups have\n",
      "    the same population mean.  The test is applied to samples from two or\n",
      "    more groups, possibly with differing sizes.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sample1, sample2, ... : array_like\n",
      "        The sample measurements for each group.  There must be at least\n",
      "        two arguments.  If the arrays are multidimensional, then all the\n",
      "        dimensions of the array must be the same except for `axis`.\n",
      "    axis : int or None, default: 0\n",
      "        If an int, the axis of the input along which to compute the statistic.\n",
      "        The statistic of each axis-slice (e.g. row) of the input will appear in a\n",
      "        corresponding element of the output.\n",
      "        If ``None``, the input will be raveled before computing the statistic.\n",
      "    nan_policy : {'propagate', 'omit', 'raise'}\n",
      "        Defines how to handle input NaNs.\n",
      "        \n",
      "        - ``propagate``: if a NaN is present in the axis slice (e.g. row) along\n",
      "          which the  statistic is computed, the corresponding entry of the output\n",
      "          will be NaN.\n",
      "        - ``omit``: NaNs will be omitted when performing the calculation.\n",
      "          If insufficient data remains in the axis slice along which the\n",
      "          statistic is computed, the corresponding entry of the output will be\n",
      "          NaN.\n",
      "        - ``raise``: if a NaN is present, a ``ValueError`` will be raised.\n",
      "    keepdims : bool, default: False\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float\n",
      "        The computed F statistic of the test.\n",
      "    pvalue : float\n",
      "        The associated p-value from the F distribution.\n",
      "    \n",
      "    Warns\n",
      "    -----\n",
      "    `~scipy.stats.ConstantInputWarning`\n",
      "        Raised if all values within each of the input arrays are identical.\n",
      "        In this case the F statistic is either infinite or isn't defined,\n",
      "        so ``np.inf`` or ``np.nan`` is returned.\n",
      "    `~scipy.stats.DegenerateDataWarning`\n",
      "        Raised if the length of any input array is 0, or if all the input\n",
      "        arrays have length 1.  ``np.nan`` is returned for the F statistic\n",
      "        and the p-value in these cases.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The ANOVA test has important assumptions that must be satisfied in order\n",
      "    for the associated p-value to be valid.\n",
      "    \n",
      "    1. The samples are independent.\n",
      "    2. Each sample is from a normally distributed population.\n",
      "    3. The population standard deviations of the groups are all equal.  This\n",
      "       property is known as homoscedasticity.\n",
      "    \n",
      "    If these assumptions are not true for a given set of data, it may still\n",
      "    be possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`) or\n",
      "    the Alexander-Govern test (`scipy.stats.alexandergovern`) although with\n",
      "    some loss of power.\n",
      "    \n",
      "    The length of each group must be at least one, and there must be at\n",
      "    least one group with length greater than one.  If these conditions\n",
      "    are not satisfied, a warning is generated and (``np.nan``, ``np.nan``)\n",
      "    is returned.\n",
      "    \n",
      "    If all values in each group are identical, and there exist at least two\n",
      "    groups with different values, the function generates a warning and\n",
      "    returns (``np.inf``, 0).\n",
      "    \n",
      "    If all values in all groups are the same, function generates a warning\n",
      "    and returns (``np.nan``, ``np.nan``).\n",
      "    \n",
      "    The algorithm is from Heiman [2]_, pp.394-7.\n",
      "    \n",
      "    Beginning in SciPy 1.9, ``np.matrix`` inputs (not recommended for new\n",
      "    code) are converted to ``np.ndarray`` before the calculation is performed. In\n",
      "    this case, the output will be a scalar or ``np.ndarray`` of appropriate shape\n",
      "    rather than a 2D ``np.matrix``. Similarly, while masked elements of masked\n",
      "    arrays are ignored, the output will be a scalar or ``np.ndarray`` rather than a\n",
      "    masked array with ``mask=False``.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] R. Lowry, \"Concepts and Applications of Inferential Statistics\",\n",
      "           Chapter 14, 2014, http://vassarstats.net/textbook/\n",
      "    \n",
      "    .. [2] G.W. Heiman, \"Understanding research methods and statistics: An\n",
      "           integrated introduction for psychology\", Houghton, Mifflin and\n",
      "           Company, 2001.\n",
      "    \n",
      "    .. [3] G.H. McDonald, \"Handbook of Biological Statistics\", One-way ANOVA.\n",
      "           http://www.biostathandbook.com/onewayanova.html\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from scipy.stats import f_oneway\n",
      "    \n",
      "    Here are some data [3]_ on a shell measurement (the length of the anterior\n",
      "    adductor muscle scar, standardized by dividing by length) in the mussel\n",
      "    Mytilus trossulus from five locations: Tillamook, Oregon; Newport, Oregon;\n",
      "    Petersburg, Alaska; Magadan, Russia; and Tvarminne, Finland, taken from a\n",
      "    much larger data set used in McDonald et al. (1991).\n",
      "    \n",
      "    >>> tillamook = [0.0571, 0.0813, 0.0831, 0.0976, 0.0817, 0.0859, 0.0735,\n",
      "    ...              0.0659, 0.0923, 0.0836]\n",
      "    >>> newport = [0.0873, 0.0662, 0.0672, 0.0819, 0.0749, 0.0649, 0.0835,\n",
      "    ...            0.0725]\n",
      "    >>> petersburg = [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105]\n",
      "    >>> magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764,\n",
      "    ...            0.0689]\n",
      "    >>> tvarminne = [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]\n",
      "    >>> f_oneway(tillamook, newport, petersburg, magadan, tvarminne)\n",
      "    F_onewayResult(statistic=7.121019471642447, pvalue=0.0002812242314534544)\n",
      "    \n",
      "    `f_oneway` accepts multidimensional input arrays.  When the inputs\n",
      "    are multidimensional and `axis` is not given, the test is performed\n",
      "    along the first axis of the input arrays.  For the following data, the\n",
      "    test is performed three times, once for each column.\n",
      "    \n",
      "    >>> a = np.array([[9.87, 9.03, 6.81],\n",
      "    ...               [7.18, 8.35, 7.00],\n",
      "    ...               [8.39, 7.58, 7.68],\n",
      "    ...               [7.45, 6.33, 9.35],\n",
      "    ...               [6.41, 7.10, 9.33],\n",
      "    ...               [8.00, 8.24, 8.44]])\n",
      "    >>> b = np.array([[6.35, 7.30, 7.16],\n",
      "    ...               [6.65, 6.68, 7.63],\n",
      "    ...               [5.72, 7.73, 6.72],\n",
      "    ...               [7.01, 9.19, 7.41],\n",
      "    ...               [7.75, 7.87, 8.30],\n",
      "    ...               [6.90, 7.97, 6.97]])\n",
      "    >>> c = np.array([[3.31, 8.77, 1.01],\n",
      "    ...               [8.25, 3.24, 3.62],\n",
      "    ...               [6.32, 8.81, 5.19],\n",
      "    ...               [7.48, 8.83, 8.91],\n",
      "    ...               [8.59, 6.01, 6.07],\n",
      "    ...               [3.07, 9.72, 7.48]])\n",
      "    >>> F, p = f_oneway(a, b, c)\n",
      "    >>> F\n",
      "    array([1.75676344, 0.03701228, 3.76439349])\n",
      "    >>> p\n",
      "    array([0.20630784, 0.96375203, 0.04733157])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "dir(scipy.stats) # f_oneway\n",
    "help(scipy.stats.f_oneway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e499dfd9-1862-4f8b-9df5-79f3ba14d54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.884107946026987 1.752985223798021e-05\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# 각 그룹의 데이터\n",
    "groupA = [85, 92, 78, 88, 83, 90, 76, 84, 92, 87]\n",
    "groupB = [79, 69, 84, 78, 79, 83, 79, 81, 86, 88]\n",
    "groupC = [75, 68, 74, 65, 77, 72, 70, 73, 78, 75]\n",
    "\n",
    "cv, pv = f_oneway(groupA, groupB, groupC)\n",
    "\n",
    "print(cv, pv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7638b-d04c-4b2a-a929-7f50df0ea7f8",
   "metadata": {},
   "source": [
    "12명의 수험생이 빅데이터 분석기사 시험에서 받은 점수이다. Shapiro-Wilk 검정을 사용하여 데이터가 정규 분포를 따르는지 검증하시오\r\n",
    "귀무 가설(H0): 데이터는 정규 분포를 따른다.\r\n",
    "대립 가설(H1): 데이터는 정규 분포를 따르지 않는다.\r\n",
    "Shapiro-Wilk 검정 통계량, p-value, 검증결과를 출력\n",
    "\n",
    "Shapiro-Wilk 검정는 정규분포를 따르는지 확인하는검정하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "374d075e-d948-4141-a9de-ecd67bbd5ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768091723993144 0.9676506711851194\n",
      "데이터는 정규분포를 따른다\n"
     ]
    }
   ],
   "source": [
    "# dir(scipy.stats)\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "data = [75, 83, 81, 92, 68, 77, 78, 80, 85, 95, 79, 89]\n",
    "\n",
    "cv, pv = shapiro(data)\n",
    "print(cv, pv)\n",
    "\n",
    "if pv <= 0.05:\n",
    "    print(\"귀무가설 기각\")\n",
    "else:\n",
    "    print(\"데이터는 정규분포를 따른다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e8dd4-3153-4706-8255-46678d989045",
   "metadata": {},
   "source": [
    "iris에서 Sepal Length와 Sepal Width의 상관계수 계산하고 소수 둘째자리까지 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "704c87d1-2ad7-4474-aa2f-7d0b62e9b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# iris 데이터셋 로드\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "856aab30-cc75-40d6-b81d-41ad4944649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)\n",
      "0                  5.1               3.5\n",
      "1                  4.9               3.0\n",
      "2                  4.7               3.2\n",
      "3                  4.6               3.1\n",
      "4                  5.0               3.6\n",
      "..                 ...               ...\n",
      "145                6.7               3.0\n",
      "146                6.3               2.5\n",
      "147                6.5               3.0\n",
      "148                6.2               3.4\n",
      "149                5.9               3.0\n",
      "\n",
      "[150 rows x 2 columns]\n",
      "-0.11756978413300088\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "\n",
    "new_df = df[['sepal length (cm)', 'sepal width (cm)']]\n",
    "print(new_df)\n",
    "\n",
    "# print(new_df.corr())\n",
    "print(new_df.corr().loc['sepal length (cm)', 'sepal width (cm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4e31580-3183-43b7-8cf6-d062b00975d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BootstrapMethod',\n",
       " 'CensoredData',\n",
       " 'ConstantInputWarning',\n",
       " 'Covariance',\n",
       " 'DegenerateDataWarning',\n",
       " 'FitError',\n",
       " 'MonteCarloMethod',\n",
       " 'NearConstantInputWarning',\n",
       " 'PermutationMethod',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_ansari_swilk_statistics',\n",
       " '_axis_nan_policy',\n",
       " '_biasedurn',\n",
       " '_binned_statistic',\n",
       " '_binomtest',\n",
       " '_boost',\n",
       " '_bws_test',\n",
       " '_censored_data',\n",
       " '_common',\n",
       " '_constants',\n",
       " '_continuous_distns',\n",
       " '_covariance',\n",
       " '_crosstab',\n",
       " '_discrete_distns',\n",
       " '_distn_infrastructure',\n",
       " '_distr_params',\n",
       " '_entropy',\n",
       " '_fit',\n",
       " '_hypotests',\n",
       " '_kde',\n",
       " '_ksstats',\n",
       " '_levy_stable',\n",
       " '_mannwhitneyu',\n",
       " '_morestats',\n",
       " '_mstats_basic',\n",
       " '_mstats_extras',\n",
       " '_multicomp',\n",
       " '_multivariate',\n",
       " '_mvn',\n",
       " '_odds_ratio',\n",
       " '_page_trend_test',\n",
       " '_qmc',\n",
       " '_qmc_cy',\n",
       " '_qmvnt',\n",
       " '_rcont',\n",
       " '_relative_risk',\n",
       " '_resampling',\n",
       " '_rvs_sampling',\n",
       " '_sampling',\n",
       " '_sensitivity_analysis',\n",
       " '_sobol',\n",
       " '_stats',\n",
       " '_stats_mstats_common',\n",
       " '_stats_py',\n",
       " '_stats_pythran',\n",
       " '_survival',\n",
       " '_tukeylambda_stats',\n",
       " '_unuran',\n",
       " '_variation',\n",
       " '_warnings_errors',\n",
       " '_wilcoxon',\n",
       " 'alexandergovern',\n",
       " 'alpha',\n",
       " 'anderson',\n",
       " 'anderson_ksamp',\n",
       " 'anglit',\n",
       " 'ansari',\n",
       " 'arcsine',\n",
       " 'argus',\n",
       " 'barnard_exact',\n",
       " 'bartlett',\n",
       " 'bayes_mvs',\n",
       " 'bernoulli',\n",
       " 'beta',\n",
       " 'betabinom',\n",
       " 'betanbinom',\n",
       " 'betaprime',\n",
       " 'biasedurn',\n",
       " 'binned_statistic',\n",
       " 'binned_statistic_2d',\n",
       " 'binned_statistic_dd',\n",
       " 'binom',\n",
       " 'binomtest',\n",
       " 'boltzmann',\n",
       " 'bootstrap',\n",
       " 'boschloo_exact',\n",
       " 'boxcox',\n",
       " 'boxcox_llf',\n",
       " 'boxcox_normmax',\n",
       " 'boxcox_normplot',\n",
       " 'bradford',\n",
       " 'brunnermunzel',\n",
       " 'burr',\n",
       " 'burr12',\n",
       " 'bws_test',\n",
       " 'cauchy',\n",
       " 'chi',\n",
       " 'chi2',\n",
       " 'chi2_contingency',\n",
       " 'chisquare',\n",
       " 'circmean',\n",
       " 'circstd',\n",
       " 'circvar',\n",
       " 'combine_pvalues',\n",
       " 'contingency',\n",
       " 'cosine',\n",
       " 'cramervonmises',\n",
       " 'cramervonmises_2samp',\n",
       " 'crystalball',\n",
       " 'cumfreq',\n",
       " 'describe',\n",
       " 'dgamma',\n",
       " 'differential_entropy',\n",
       " 'directional_stats',\n",
       " 'dirichlet',\n",
       " 'dirichlet_multinomial',\n",
       " 'distributions',\n",
       " 'dlaplace',\n",
       " 'dunnett',\n",
       " 'dweibull',\n",
       " 'ecdf',\n",
       " 'energy_distance',\n",
       " 'entropy',\n",
       " 'epps_singleton_2samp',\n",
       " 'erlang',\n",
       " 'expectile',\n",
       " 'expon',\n",
       " 'exponnorm',\n",
       " 'exponpow',\n",
       " 'exponweib',\n",
       " 'f',\n",
       " 'f_oneway',\n",
       " 'false_discovery_control',\n",
       " 'fatiguelife',\n",
       " 'find_repeats',\n",
       " 'fisher_exact',\n",
       " 'fisk',\n",
       " 'fit',\n",
       " 'fligner',\n",
       " 'foldcauchy',\n",
       " 'foldnorm',\n",
       " 'friedmanchisquare',\n",
       " 'gamma',\n",
       " 'gausshyper',\n",
       " 'gaussian_kde',\n",
       " 'genexpon',\n",
       " 'genextreme',\n",
       " 'gengamma',\n",
       " 'genhalflogistic',\n",
       " 'genhyperbolic',\n",
       " 'geninvgauss',\n",
       " 'genlogistic',\n",
       " 'gennorm',\n",
       " 'genpareto',\n",
       " 'geom',\n",
       " 'gibrat',\n",
       " 'gmean',\n",
       " 'gompertz',\n",
       " 'goodness_of_fit',\n",
       " 'gstd',\n",
       " 'gumbel_l',\n",
       " 'gumbel_r',\n",
       " 'gzscore',\n",
       " 'halfcauchy',\n",
       " 'halfgennorm',\n",
       " 'halflogistic',\n",
       " 'halfnorm',\n",
       " 'hmean',\n",
       " 'hypergeom',\n",
       " 'hypsecant',\n",
       " 'invgamma',\n",
       " 'invgauss',\n",
       " 'invweibull',\n",
       " 'invwishart',\n",
       " 'iqr',\n",
       " 'jarque_bera',\n",
       " 'jf_skew_t',\n",
       " 'johnsonsb',\n",
       " 'johnsonsu',\n",
       " 'kappa3',\n",
       " 'kappa4',\n",
       " 'kde',\n",
       " 'kendalltau',\n",
       " 'kruskal',\n",
       " 'ks_1samp',\n",
       " 'ks_2samp',\n",
       " 'ksone',\n",
       " 'kstat',\n",
       " 'kstatvar',\n",
       " 'kstest',\n",
       " 'kstwo',\n",
       " 'kstwobign',\n",
       " 'kurtosis',\n",
       " 'kurtosistest',\n",
       " 'laplace',\n",
       " 'laplace_asymmetric',\n",
       " 'levene',\n",
       " 'levy',\n",
       " 'levy_l',\n",
       " 'levy_stable',\n",
       " 'linregress',\n",
       " 'loggamma',\n",
       " 'logistic',\n",
       " 'loglaplace',\n",
       " 'lognorm',\n",
       " 'logrank',\n",
       " 'logser',\n",
       " 'loguniform',\n",
       " 'lomax',\n",
       " 'mannwhitneyu',\n",
       " 'matrix_normal',\n",
       " 'maxwell',\n",
       " 'median_abs_deviation',\n",
       " 'median_test',\n",
       " 'mielke',\n",
       " 'mode',\n",
       " 'moment',\n",
       " 'monte_carlo_test',\n",
       " 'mood',\n",
       " 'morestats',\n",
       " 'moyal',\n",
       " 'mstats',\n",
       " 'mstats_basic',\n",
       " 'mstats_extras',\n",
       " 'multinomial',\n",
       " 'multiscale_graphcorr',\n",
       " 'multivariate_hypergeom',\n",
       " 'multivariate_normal',\n",
       " 'multivariate_t',\n",
       " 'mvn',\n",
       " 'mvsdist',\n",
       " 'nakagami',\n",
       " 'nbinom',\n",
       " 'ncf',\n",
       " 'nchypergeom_fisher',\n",
       " 'nchypergeom_wallenius',\n",
       " 'nct',\n",
       " 'ncx2',\n",
       " 'nhypergeom',\n",
       " 'norm',\n",
       " 'normaltest',\n",
       " 'norminvgauss',\n",
       " 'obrientransform',\n",
       " 'ortho_group',\n",
       " 'page_trend_test',\n",
       " 'pareto',\n",
       " 'pearson3',\n",
       " 'pearsonr',\n",
       " 'percentileofscore',\n",
       " 'permutation_test',\n",
       " 'planck',\n",
       " 'pmean',\n",
       " 'pointbiserialr',\n",
       " 'poisson',\n",
       " 'poisson_means_test',\n",
       " 'power_divergence',\n",
       " 'powerlaw',\n",
       " 'powerlognorm',\n",
       " 'powernorm',\n",
       " 'ppcc_max',\n",
       " 'ppcc_plot',\n",
       " 'probplot',\n",
       " 'qmc',\n",
       " 'quantile_test',\n",
       " 'randint',\n",
       " 'random_correlation',\n",
       " 'random_table',\n",
       " 'rankdata',\n",
       " 'ranksums',\n",
       " 'rayleigh',\n",
       " 'rdist',\n",
       " 'recipinvgauss',\n",
       " 'reciprocal',\n",
       " 'rel_breitwigner',\n",
       " 'relfreq',\n",
       " 'rice',\n",
       " 'rv_continuous',\n",
       " 'rv_discrete',\n",
       " 'rv_histogram',\n",
       " 'rvs_ratio_uniforms',\n",
       " 'sampling',\n",
       " 'scoreatpercentile',\n",
       " 'sem',\n",
       " 'semicircular',\n",
       " 'shapiro',\n",
       " 'siegelslopes',\n",
       " 'sigmaclip',\n",
       " 'skellam',\n",
       " 'skew',\n",
       " 'skewcauchy',\n",
       " 'skewnorm',\n",
       " 'skewtest',\n",
       " 'sobol_indices',\n",
       " 'somersd',\n",
       " 'spearmanr',\n",
       " 'special_ortho_group',\n",
       " 'stats',\n",
       " 'studentized_range',\n",
       " 't',\n",
       " 'test',\n",
       " 'theilslopes',\n",
       " 'tiecorrect',\n",
       " 'tmax',\n",
       " 'tmean',\n",
       " 'tmin',\n",
       " 'trapezoid',\n",
       " 'trapz',\n",
       " 'triang',\n",
       " 'trim1',\n",
       " 'trim_mean',\n",
       " 'trimboth',\n",
       " 'truncexpon',\n",
       " 'truncnorm',\n",
       " 'truncpareto',\n",
       " 'truncweibull_min',\n",
       " 'tsem',\n",
       " 'tstd',\n",
       " 'ttest_1samp',\n",
       " 'ttest_ind',\n",
       " 'ttest_ind_from_stats',\n",
       " 'ttest_rel',\n",
       " 'tukey_hsd',\n",
       " 'tukeylambda',\n",
       " 'tvar',\n",
       " 'uniform',\n",
       " 'uniform_direction',\n",
       " 'unitary_group',\n",
       " 'variation',\n",
       " 'vonmises',\n",
       " 'vonmises_fisher',\n",
       " 'vonmises_line',\n",
       " 'wald',\n",
       " 'wasserstein_distance',\n",
       " 'wasserstein_distance_nd',\n",
       " 'weibull_max',\n",
       " 'weibull_min',\n",
       " 'weightedtau',\n",
       " 'wilcoxon',\n",
       " 'wishart',\n",
       " 'wrapcauchy',\n",
       " 'yeojohnson',\n",
       " 'yeojohnson_llf',\n",
       " 'yeojohnson_normmax',\n",
       " 'yeojohnson_normplot',\n",
       " 'yulesimon',\n",
       " 'zipf',\n",
       " 'zipfian',\n",
       " 'zmap',\n",
       " 'zscore']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(scipy.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614981c4-ef79-466c-9d87-799117a8a064",
   "metadata": {},
   "source": [
    "로지스틱 회귀에 대해서...\n",
    "\n",
    "Pclass, Gender, sibsp, parch를 독립변수로 사용하여 로지스틱 회귀모형을 실시하였을 때, parch변수의 계수값은? 단, Pclass는 범주형 변수이다\r\n",
    "(반올림하여 소수 셋째 자리까지 계산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac9667e-d82f-41bc-b8a0-482a576315b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Gender   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a14db65-960e-4a07-8bcc-26df7b92e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.459565\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Intercept         2.491729\n",
       "C(Pclass)[T.2]   -0.848152\n",
       "C(Pclass)[T.3]   -1.866905\n",
       "Gender           -2.760281\n",
       "SibSp            -0.232553\n",
       "Parch            -0.049847\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.formula.api import logit\n",
    "df.columns\n",
    "\n",
    "formula = \"Survived ~ C(Pclass) + Gender + SibSp + Parch\"\n",
    "model = logit(formula, data = df).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af8b436-b956-44df-9e1f-e701714b5fd9",
   "metadata": {},
   "source": [
    "로지스틱 회귀2\n",
    "\n",
    "\n",
    "고객 정보를 나타낸 데이터이다. 주어진 데이터에서 500개 중 앞에서부터 350개는 train으로, 150개는 test 데이터로 나눈다. 모델을 학습(적합)할 때는 train 데이터를 사용하고, 예측할 때는 test 데이터를 사용한다. 모델은 로지스틱 회귀를 써서 고객이 특정 제품을 구매할지 여부를 예측하되, 페널티는 부과하지 않는다.\r\n",
    "\r\n",
    "종속변수: purchase (0: 구매 안 함, 1: 구매 함)\r\n",
    "\r\n",
    "문제 1-1. income 변수를 독립변수로 purchase를 종속변수로 사용하여 로지스틱 회귀 모형을 만들고, income 변수가 한 단위 증가할 때 구매할 오즈비 값을 계산하시오. (반올림하여 소수 넷째자리까지 계산)\r\n",
    "\r\n",
    "문제 1-2. 독립변수 income만 사용해 학습한 모델에서 test 데이터의 purchase를 예측하고, accuracy (정확도)를 구하시오. (반올림하여 소수 셋째자리까지 계산)\r\n",
    "\r\n",
    "문제 1-3. 독립변수 income만 사용해 학습한 모델의 로짓 우도를 계산하시오.\r\n",
    "\r\n",
    "문제 1-4. 독립변수 income만 사용해 학습한 모델의 유의확률(p-value)를 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ee7836-1e59-4b03-86ec-315885369952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>children</th>\n",
       "      <th>gender</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>111980</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>107314</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>56209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>28010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>79618</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  marital_status  children  gender  purchase\n",
       "0   62  111980               1         2       1         0\n",
       "1   65  107314               0         3       1         0\n",
       "2   18   56209               1         1       1         1\n",
       "3   21   28010               1         3       0         1\n",
       "4   21   79618               0         2       0         1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Customer_Data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7262852d-7387-4624-95d5-43995244c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692599\n",
      "         Iterations 3\n",
      "1.0000019601805765\n",
      "0.5066666666666667\n",
      "0.5964910811075123\n"
     ]
    }
   ],
   "source": [
    "train = df.iloc[:350]\n",
    "test = df.iloc[350:]\n",
    "\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "model = logit('purchase ~ income', data = train).fit() # y ~ x\n",
    "log_odds = model.params['income'] # 로그 오즈 값\n",
    "\n",
    "import numpy as np\n",
    "odds = np.exp(log_odds)\n",
    "print(odds)\n",
    "\n",
    "pred = model.predict(test)\n",
    "result = (pred > 0.5).astype(int)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = (result == test['purchase']).mean()\n",
    "print(accuracy)\n",
    "\n",
    "# 유의확률\n",
    "print(model.pvalues['income'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392e845-a311-4e78-9c30-738767302fc2",
   "metadata": {},
   "source": [
    "두 그룹 간 평균 비교\n",
    "\n",
    "문제: 두 교육 방법의 효과 비교\r\n",
    "연구자는 두 가지 다른 교육 방법이 학생들의 성적에 미치는 영향을 비교하고자 합니다. 연구자는 무작위로 선발된 20명의 학생들을 두 그룹으로 나누어 한 그룹에는 교육 방법 A를, 다른 그룹에는 교육 방법 B를 적용합니다. 교육이 끝난 후, 두 그룹의 성적을 비교하기 위해 독립 표본 t-검정과 ANOVA F-검정을 실시하려고 합니다.\r\n",
    "\r\n",
    "다음은 두 그룹의 성적입니다: 다음의 두 가지 검정을 사용하여 두 교육 방법 간의 성적 차이가 통계적으로 유의한지를 검증하세요\r\n",
    "\r\n",
    "독립 표본 t-검정을 실시하여 t 통계량을 구하세요.\r\n",
    "독립 표본 t-검정을 실시하여 p-값을 구하세요.\r\n",
    "ANOVA F-검정을 실시하여 F 통계량을 구하세요.\r\n",
    "ANOVA F-검정을 실시하여 p-값을 구하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7545757f-4884-46b8-ada6-2c688d1f89fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1068522301122954 0.006087373605949963\n",
      "9.652530779753763 0.006087373605949924\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A':[77, 75, 82, 80, 81, 83, 84, 76, 75, 87],\n",
    "    'B':[80, 74, 77, 79, 71, 74, 78, 69, 70, 72],\n",
    "})\n",
    "\n",
    "#1. 독립 표본 t-검정\n",
    "cv, pv = ttest_ind(df['A'], df['B'])\n",
    "print(cv, pv)\n",
    "\n",
    "cv, pv = f_oneway(df['A'], df['B'])\n",
    "print(cv, pv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "610caa95-c949-48b6-ba73-2494234facdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BootstrapMethod',\n",
       " 'CensoredData',\n",
       " 'ConstantInputWarning',\n",
       " 'Covariance',\n",
       " 'DegenerateDataWarning',\n",
       " 'FitError',\n",
       " 'MonteCarloMethod',\n",
       " 'NearConstantInputWarning',\n",
       " 'PermutationMethod',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_ansari_swilk_statistics',\n",
       " '_axis_nan_policy',\n",
       " '_biasedurn',\n",
       " '_binned_statistic',\n",
       " '_binomtest',\n",
       " '_boost',\n",
       " '_bws_test',\n",
       " '_censored_data',\n",
       " '_common',\n",
       " '_constants',\n",
       " '_continuous_distns',\n",
       " '_covariance',\n",
       " '_crosstab',\n",
       " '_discrete_distns',\n",
       " '_distn_infrastructure',\n",
       " '_distr_params',\n",
       " '_entropy',\n",
       " '_fit',\n",
       " '_hypotests',\n",
       " '_kde',\n",
       " '_ksstats',\n",
       " '_levy_stable',\n",
       " '_mannwhitneyu',\n",
       " '_morestats',\n",
       " '_mstats_basic',\n",
       " '_mstats_extras',\n",
       " '_multicomp',\n",
       " '_multivariate',\n",
       " '_mvn',\n",
       " '_odds_ratio',\n",
       " '_page_trend_test',\n",
       " '_qmc',\n",
       " '_qmc_cy',\n",
       " '_qmvnt',\n",
       " '_rcont',\n",
       " '_relative_risk',\n",
       " '_resampling',\n",
       " '_rvs_sampling',\n",
       " '_sampling',\n",
       " '_sensitivity_analysis',\n",
       " '_sobol',\n",
       " '_stats',\n",
       " '_stats_mstats_common',\n",
       " '_stats_py',\n",
       " '_stats_pythran',\n",
       " '_survival',\n",
       " '_tukeylambda_stats',\n",
       " '_unuran',\n",
       " '_variation',\n",
       " '_warnings_errors',\n",
       " '_wilcoxon',\n",
       " 'alexandergovern',\n",
       " 'alpha',\n",
       " 'anderson',\n",
       " 'anderson_ksamp',\n",
       " 'anglit',\n",
       " 'ansari',\n",
       " 'arcsine',\n",
       " 'argus',\n",
       " 'barnard_exact',\n",
       " 'bartlett',\n",
       " 'bayes_mvs',\n",
       " 'bernoulli',\n",
       " 'beta',\n",
       " 'betabinom',\n",
       " 'betanbinom',\n",
       " 'betaprime',\n",
       " 'biasedurn',\n",
       " 'binned_statistic',\n",
       " 'binned_statistic_2d',\n",
       " 'binned_statistic_dd',\n",
       " 'binom',\n",
       " 'binomtest',\n",
       " 'boltzmann',\n",
       " 'bootstrap',\n",
       " 'boschloo_exact',\n",
       " 'boxcox',\n",
       " 'boxcox_llf',\n",
       " 'boxcox_normmax',\n",
       " 'boxcox_normplot',\n",
       " 'bradford',\n",
       " 'brunnermunzel',\n",
       " 'burr',\n",
       " 'burr12',\n",
       " 'bws_test',\n",
       " 'cauchy',\n",
       " 'chi',\n",
       " 'chi2',\n",
       " 'chi2_contingency',\n",
       " 'chisquare',\n",
       " 'circmean',\n",
       " 'circstd',\n",
       " 'circvar',\n",
       " 'combine_pvalues',\n",
       " 'contingency',\n",
       " 'cosine',\n",
       " 'cramervonmises',\n",
       " 'cramervonmises_2samp',\n",
       " 'crystalball',\n",
       " 'cumfreq',\n",
       " 'describe',\n",
       " 'dgamma',\n",
       " 'differential_entropy',\n",
       " 'directional_stats',\n",
       " 'dirichlet',\n",
       " 'dirichlet_multinomial',\n",
       " 'distributions',\n",
       " 'dlaplace',\n",
       " 'dunnett',\n",
       " 'dweibull',\n",
       " 'ecdf',\n",
       " 'energy_distance',\n",
       " 'entropy',\n",
       " 'epps_singleton_2samp',\n",
       " 'erlang',\n",
       " 'expectile',\n",
       " 'expon',\n",
       " 'exponnorm',\n",
       " 'exponpow',\n",
       " 'exponweib',\n",
       " 'f',\n",
       " 'f_oneway',\n",
       " 'false_discovery_control',\n",
       " 'fatiguelife',\n",
       " 'find_repeats',\n",
       " 'fisher_exact',\n",
       " 'fisk',\n",
       " 'fit',\n",
       " 'fligner',\n",
       " 'foldcauchy',\n",
       " 'foldnorm',\n",
       " 'friedmanchisquare',\n",
       " 'gamma',\n",
       " 'gausshyper',\n",
       " 'gaussian_kde',\n",
       " 'genexpon',\n",
       " 'genextreme',\n",
       " 'gengamma',\n",
       " 'genhalflogistic',\n",
       " 'genhyperbolic',\n",
       " 'geninvgauss',\n",
       " 'genlogistic',\n",
       " 'gennorm',\n",
       " 'genpareto',\n",
       " 'geom',\n",
       " 'gibrat',\n",
       " 'gmean',\n",
       " 'gompertz',\n",
       " 'goodness_of_fit',\n",
       " 'gstd',\n",
       " 'gumbel_l',\n",
       " 'gumbel_r',\n",
       " 'gzscore',\n",
       " 'halfcauchy',\n",
       " 'halfgennorm',\n",
       " 'halflogistic',\n",
       " 'halfnorm',\n",
       " 'hmean',\n",
       " 'hypergeom',\n",
       " 'hypsecant',\n",
       " 'invgamma',\n",
       " 'invgauss',\n",
       " 'invweibull',\n",
       " 'invwishart',\n",
       " 'iqr',\n",
       " 'jarque_bera',\n",
       " 'jf_skew_t',\n",
       " 'johnsonsb',\n",
       " 'johnsonsu',\n",
       " 'kappa3',\n",
       " 'kappa4',\n",
       " 'kde',\n",
       " 'kendalltau',\n",
       " 'kruskal',\n",
       " 'ks_1samp',\n",
       " 'ks_2samp',\n",
       " 'ksone',\n",
       " 'kstat',\n",
       " 'kstatvar',\n",
       " 'kstest',\n",
       " 'kstwo',\n",
       " 'kstwobign',\n",
       " 'kurtosis',\n",
       " 'kurtosistest',\n",
       " 'laplace',\n",
       " 'laplace_asymmetric',\n",
       " 'levene',\n",
       " 'levy',\n",
       " 'levy_l',\n",
       " 'levy_stable',\n",
       " 'linregress',\n",
       " 'loggamma',\n",
       " 'logistic',\n",
       " 'loglaplace',\n",
       " 'lognorm',\n",
       " 'logrank',\n",
       " 'logser',\n",
       " 'loguniform',\n",
       " 'lomax',\n",
       " 'mannwhitneyu',\n",
       " 'matrix_normal',\n",
       " 'maxwell',\n",
       " 'median_abs_deviation',\n",
       " 'median_test',\n",
       " 'mielke',\n",
       " 'mode',\n",
       " 'moment',\n",
       " 'monte_carlo_test',\n",
       " 'mood',\n",
       " 'morestats',\n",
       " 'moyal',\n",
       " 'mstats',\n",
       " 'mstats_basic',\n",
       " 'mstats_extras',\n",
       " 'multinomial',\n",
       " 'multiscale_graphcorr',\n",
       " 'multivariate_hypergeom',\n",
       " 'multivariate_normal',\n",
       " 'multivariate_t',\n",
       " 'mvn',\n",
       " 'mvsdist',\n",
       " 'nakagami',\n",
       " 'nbinom',\n",
       " 'ncf',\n",
       " 'nchypergeom_fisher',\n",
       " 'nchypergeom_wallenius',\n",
       " 'nct',\n",
       " 'ncx2',\n",
       " 'nhypergeom',\n",
       " 'norm',\n",
       " 'normaltest',\n",
       " 'norminvgauss',\n",
       " 'obrientransform',\n",
       " 'ortho_group',\n",
       " 'page_trend_test',\n",
       " 'pareto',\n",
       " 'pearson3',\n",
       " 'pearsonr',\n",
       " 'percentileofscore',\n",
       " 'permutation_test',\n",
       " 'planck',\n",
       " 'pmean',\n",
       " 'pointbiserialr',\n",
       " 'poisson',\n",
       " 'poisson_means_test',\n",
       " 'power_divergence',\n",
       " 'powerlaw',\n",
       " 'powerlognorm',\n",
       " 'powernorm',\n",
       " 'ppcc_max',\n",
       " 'ppcc_plot',\n",
       " 'probplot',\n",
       " 'qmc',\n",
       " 'quantile_test',\n",
       " 'randint',\n",
       " 'random_correlation',\n",
       " 'random_table',\n",
       " 'rankdata',\n",
       " 'ranksums',\n",
       " 'rayleigh',\n",
       " 'rdist',\n",
       " 'recipinvgauss',\n",
       " 'reciprocal',\n",
       " 'rel_breitwigner',\n",
       " 'relfreq',\n",
       " 'rice',\n",
       " 'rv_continuous',\n",
       " 'rv_discrete',\n",
       " 'rv_histogram',\n",
       " 'rvs_ratio_uniforms',\n",
       " 'sampling',\n",
       " 'scoreatpercentile',\n",
       " 'sem',\n",
       " 'semicircular',\n",
       " 'shapiro',\n",
       " 'siegelslopes',\n",
       " 'sigmaclip',\n",
       " 'skellam',\n",
       " 'skew',\n",
       " 'skewcauchy',\n",
       " 'skewnorm',\n",
       " 'skewtest',\n",
       " 'sobol_indices',\n",
       " 'somersd',\n",
       " 'spearmanr',\n",
       " 'special_ortho_group',\n",
       " 'stats',\n",
       " 'studentized_range',\n",
       " 't',\n",
       " 'test',\n",
       " 'theilslopes',\n",
       " 'tiecorrect',\n",
       " 'tmax',\n",
       " 'tmean',\n",
       " 'tmin',\n",
       " 'trapezoid',\n",
       " 'trapz',\n",
       " 'triang',\n",
       " 'trim1',\n",
       " 'trim_mean',\n",
       " 'trimboth',\n",
       " 'truncexpon',\n",
       " 'truncnorm',\n",
       " 'truncpareto',\n",
       " 'truncweibull_min',\n",
       " 'tsem',\n",
       " 'tstd',\n",
       " 'ttest_1samp',\n",
       " 'ttest_ind',\n",
       " 'ttest_ind_from_stats',\n",
       " 'ttest_rel',\n",
       " 'tukey_hsd',\n",
       " 'tukeylambda',\n",
       " 'tvar',\n",
       " 'uniform',\n",
       " 'uniform_direction',\n",
       " 'unitary_group',\n",
       " 'variation',\n",
       " 'vonmises',\n",
       " 'vonmises_fisher',\n",
       " 'vonmises_line',\n",
       " 'wald',\n",
       " 'wasserstein_distance',\n",
       " 'wasserstein_distance_nd',\n",
       " 'weibull_max',\n",
       " 'weibull_min',\n",
       " 'weightedtau',\n",
       " 'wilcoxon',\n",
       " 'wishart',\n",
       " 'wrapcauchy',\n",
       " 'yeojohnson',\n",
       " 'yeojohnson_llf',\n",
       " 'yeojohnson_normmax',\n",
       " 'yeojohnson_normplot',\n",
       " 'yulesimon',\n",
       " 'zipf',\n",
       " 'zipfian',\n",
       " 'zmap',\n",
       " 'zscore']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dir(scipy.stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980e7e1-fdaa-460b-98ee-11e05d92dd2e",
   "metadata": {},
   "source": [
    "카이제곱 적합도 검정\r\n",
    "고등학교에서는 졸업생들이 선택하는 대학 전공 분야의 선호도가 시간이 지남에 따라 변하지 않는다고 가정합니다. 학교 측은 최근 졸업생들의 전공 선택이 과거와 같은 패턴을 따르는지 알아보기 위해 적합도 검정을 실시하기로 결정했습니다.\r\n",
    "\r\n",
    "과거 자료에 따르면 졸업생들이 선택하는 전공의 분포는 다음과 같습니다:\r\n",
    "\r\n",
    "인문학: 20% 사회과학: 30% 자연과학: 25% 공학: 15% 기타: 10% 올해 졸업한 학생 200명의 전공 선택 분포는 다음과 같았습니다:\r\n",
    "\r\n",
    "인문학: 30명 사회과학: 60명 자연과학: 50명 공학: 40명 기타: 20명 이 데이터를 바탕으로, 졸업생들의 전공 선택 패턴이 과거와 유사한지를 알아보기 위해 카이제곱 적합도 검정을 실시해야 합니다. 유의 수준은 0.05로 설정합니다.\r\n",
    "\r\n",
    "검정 통계량?\r\n",
    "p-value?\r\n",
    "유의수준 하 귀무가설 기각 또는 채택?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcbe0629-064d-448d-a572-bb5a2d94b4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=5.833333333333334, pvalue=0.21194558437271782)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 관측된 빈도\n",
    "observed_frequencies = [30, 60, 50, 40, 20]\n",
    "\n",
    "# 기대된 빈도 \n",
    "expected_frequencies = [200 * 0.20, 200 * 0.30, 200 * 0.25, 200 * 0.15, 200 * 0.10]\n",
    "\n",
    "\n",
    "# 카이제곱\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# dir(scipy.stats)\n",
    "# help(chisquare)\n",
    "chisquare(observed_frequencies, expected_frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4434e-adad-485c-a5cf-b197287e860a",
   "metadata": {},
   "source": [
    "지지도, 신뢰도, 향상도\r\n",
    "'빼빼로'와 '딴짓초코'가 함께 팔린 거래의 지지도를 계산하세요.\r\n",
    "'빼빼로'가 팔린 거래 중에서 '빼빼로'와 '오징어칩'이 함께 팔린 거래의 신뢰도를 계산하세요.\r\n",
    "'빼빼로'와 '양조위빵'의 향상도를 계산하세요.\r\n",
    "지지도(A,B): A와 B가 함께 팔린 거래 횟수 / 전체 거래 횟수\r\n",
    "신뢰도(A->B): A와 B가 함께 팔린 거래 횟수 / A가 팔린 거래 횟수\r\n",
    "향상도(A,B): 신뢰도(A->B) / 지지도(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e49b4a5f-8d6b-40b0-9e3f-a699800b52a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction</th>\n",
       "      <th>빼빼로</th>\n",
       "      <th>딴짓초코</th>\n",
       "      <th>양조위빵</th>\n",
       "      <th>오징어칩</th>\n",
       "      <th>초코파이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction  빼빼로  딴짓초코  양조위빵  오징어칩  초코파이\n",
       "0            1    1     0     1     0     1\n",
       "1            2    0     1     0     1     1\n",
       "2            3    1     1     0     1     0\n",
       "3            4    1     0     1     0     0\n",
       "4            5    0     1     1     0     1\n",
       "5            6    1     0     1     1     0\n",
       "6            7    1     1     0     0     1\n",
       "7            8    0     1     0     1     1\n",
       "8            9    1     0     1     1     0\n",
       "9           10    1     0     0     1     0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 데이터\n",
    "df = pd.DataFrame({\n",
    "    'transaction': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    '빼빼로': [1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
    "    '딴짓초코': [0, 1, 1, 0, 1, 0, 1, 1, 0, 0],\n",
    "    '양조위빵': [1, 0, 0, 1, 1, 1, 0, 0, 1, 0],\n",
    "    '오징어칩': [0, 1, 1, 0, 0, 1, 0, 1, 1, 1],\n",
    "    '초코파이': [1, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3f5eb95-97fe-48b8-b0a9-a5b9253f0126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.5714285714285714\n",
      "1.1428571428571428\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 각 문제의 계산을 위한 데이터 준비\n",
    "total = df.shape[0]\n",
    "pepero = df['빼빼로'].sum()\n",
    "\n",
    "# 문제 1: 빼빼로와 딴짓초코가 함께 팔린 거래의 지지도\n",
    "pepero_and_choco = len(df[(df['빼빼로'] == 1) & (df['딴짓초코'] == 1)])\n",
    "print(pepero_and_choco / total)\n",
    "\n",
    "# 문제 2: 빼빼로가 팔린 거래 중 빼빼로와 오징어칩이 함께 팔린 거래의 신뢰도\n",
    "pepero_and_squid = len(df[(df['빼빼로'] == 1) & (df['오징어칩'] == 1)])\n",
    "print(pepero_and_squid / pepero)\n",
    "\n",
    "# 문제 3: 빼빼로와 양조위빵의 향상도\n",
    "pepero_and_bread = len(df[(df['빼빼로'] == 1) & (df['양조위빵'] == 1)])\n",
    "bread = df['양조위빵'].sum()\n",
    "print((pepero_and_bread / pepero) / (bread / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b5315-3497-44ab-a498-e77a9fee121f",
   "metadata": {},
   "source": [
    "포아송분포\r\n",
    "문제: 한 서점에서는 평균적으로 하루에 3명의 고객이 특정 잡지를 구매합니다. 이 데이터는 포아송 분포를 따른다고 가정할 때, 다음 질문에 대한 답을 구하세요.\r\n",
    "\r\n",
    "하루에 정확히 5명의 고객이 잡지를 구매할 확률은 얼마입니까? (%로 값을 정수로 입력하시오)\r\n",
    "하루에 적어도 2명의 고객이 잡지를 구매할 확률은 얼마입니까? (%로 값을 정수로 입력하시오)\r\n",
    "포아송 분포의 확률 \n",
    "\n",
    "질량 함수(PMF)image.png\r\n",
    "\r\n",
    "λ는 단위 시간(또는 단위 공간)당 평균 발생 횟수이고, k는 특정 시간(또는 공간) 동안의 이벤트 발생 횟수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a921d34-e2f4-4742-aacb-c62ea38407bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10081881344492458\n",
      "0.8008517265285442\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "mean = 3\n",
    "\n",
    "# 하루에 정확히 5명의 고객이 잡지를 구매할 확률\n",
    "print(poisson.pmf(5, mean))\n",
    "\n",
    "# 하루에 적어도 2명의 고객이 잡지를 구매할 확률 -> 2 명과 3명\n",
    "print(1- poisson.cdf(1, mean)) # cdf는 누적 확률을 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278f942-9062-4478-bb04-2185db4b4d08",
   "metadata": {},
   "source": [
    "성별과 시험합격은 독립적인가를 검정하시오!\r\n",
    "1 검정 통계량?\r\n",
    "2 p-value?\r\n",
    "3 귀무가설 기준 (기각/채택)?\r\n",
    "4 남자의 합격 기대\n",
    "\n",
    "chi2는 카이제곱 분포를 나타내는 객체\n",
    "chi2_contingency는 카이제곱 독립성 검정을 위한 것 빈도?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1509d45-33df-4b51-89e1-a55490595130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>합격</th>\n",
       "      <th>불합격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>남성</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>여성</th>\n",
       "      <td>130</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     합격  불합격\n",
       "남성  100  200\n",
       "여성  130  170"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'합격': [100, 130], \"불합격\": [200, 170]}, index = ['남성', '여성'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad9407b9-82cc-4507-b8e6-e4d93d1760e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=5.929494712103407, pvalue=0.01488951060599475, dof=1, expected_freq=array([[115., 185.],\n",
       "       [115., 185.]]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "chi2_contingency(df)\n",
    "\n",
    "# help(chi2_contingency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb32275-735c-4d81-915b-4035b483ad88",
   "metadata": {},
   "source": [
    "베르누이 분포와 이항분포**\r\n",
    "[베르누이 분포] 다음 데이터는 100번의 시도에서 각각 성공(1) 또는 실패(0)를 나타냅니다. 이 데이터를 바탕으로 각 시도의 성공 확률을 계산하시오.\r\n",
    "[이항분포] 1번 문제에서 계산한 성공 확률을 사용하여, 100번의 시도 중 정확히 60번 성공할 확률을 계산하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9157cfeb-c5fb-4e64-8f4c-78b204869ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Success\n",
       "0        1\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"t3_success.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "738c5a9c-6f16-41b7-b48c-14515423ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success    0.62\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.07464986])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성공확률 \n",
    "pro = df.sum()/len(df)\n",
    "print(pro)\n",
    "\n",
    "from scipy.stats import binom\n",
    "# 이항분포\n",
    "binom.pmf(60, 100, pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36443465-240c-4862-9874-910029f79be3",
   "metadata": {},
   "source": [
    "점 추정과 구간 추정\r\n",
    "데이터셋은 어떤 도시의 일일 평균 온도 입니다.\r\n",
    "\r\n",
    "점추정: 데이터셋을 기반으로 이 도시의 평균 연간 온도를 점추정하세요. (반올림하여 소수 둘째자리까지)\r\n",
    "구간추정: 95% 신뢰수준에서 이 도시의 평균 연간 온도에 대한 신뢰구간을 구하세요. (반올림하여 소수 둘째자리까지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "efe6d993-9eb1-49b2-870b-87dc0bc43e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily Average Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.820262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.893690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.204466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.337790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>23.492286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>20.018854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>24.659242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>21.699825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>19.921589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Daily Average Temperature\n",
       "0                    28.820262\n",
       "1                    22.000786\n",
       "2                    24.893690\n",
       "3                    31.204466\n",
       "4                    29.337790\n",
       "..                         ...\n",
       "360                  23.492286\n",
       "361                  20.018854\n",
       "362                  24.659242\n",
       "363                  21.699825\n",
       "364                  19.921589\n",
       "\n",
       "[365 rows x 1 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "temperature_data = pd.read_csv(\"daily_temperatures.csv\")\n",
    "temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d467f899-384f-475c-b2e7-a2ddb313d364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([19.42788709]), array([20.44726799]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#점추정\n",
    "temperature_data.mean()\n",
    "sample_std = temperature_data.std()\n",
    "#구간추정 t.interval\n",
    "\n",
    "import scipy.stats\n",
    "# help(scipy.stats.t.interval) # 외우기 어렵다.\n",
    "scipy.stats.t.interval(0.95, \n",
    "                       df = len(temperature_data)-1, \n",
    "                       loc = temperature_data.mean(), \n",
    "                       scale = sample_std/(len(temperature_data)**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97a330-9dca-4c19-8e3e-a8f9cc056382",
   "metadata": {},
   "source": [
    "크리스마스 장식 종류와 지역에 따라 판매량에 유의미한 차이가 있는지 이원 분산 분석을 통해 검정하세요\r\n",
    "크리스마스 장식 종류(트리, 조명, 장식품)가 판매량에 미치는 영향을 분석하세요. 이때, 장식 종류의 F-value, p-value를 구하시오\r\n",
    "지역(북부, 남부, 동부, 서부)이 판매량에 미치는 영향을 분석하세요. 이때, 장식 종류의 F-value, p-value를 구하시오\r\n",
    "크리스마스 장식 종류와 지역의 상호작용이 판매량에 미치는 영향을 분석하세요. 이때, 장식 종류의 F-value, p-value를 구시오\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b37f5955-c055-465c-90e7-eb37f6db4860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decoration_Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>트리</td>\n",
       "      <td>북부</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>트리</td>\n",
       "      <td>남부</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>트리</td>\n",
       "      <td>동부</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>트리</td>\n",
       "      <td>서부</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>트리</td>\n",
       "      <td>북부</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>트리</td>\n",
       "      <td>남부</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>트리</td>\n",
       "      <td>동부</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>트리</td>\n",
       "      <td>서부</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>트리</td>\n",
       "      <td>북부</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>트리</td>\n",
       "      <td>남부</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>트리</td>\n",
       "      <td>동부</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>트리</td>\n",
       "      <td>서부</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>조명</td>\n",
       "      <td>북부</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>조명</td>\n",
       "      <td>남부</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>조명</td>\n",
       "      <td>동부</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>조명</td>\n",
       "      <td>서부</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>조명</td>\n",
       "      <td>북부</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>조명</td>\n",
       "      <td>남부</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>조명</td>\n",
       "      <td>동부</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>조명</td>\n",
       "      <td>서부</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>조명</td>\n",
       "      <td>북부</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>조명</td>\n",
       "      <td>남부</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>조명</td>\n",
       "      <td>동부</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>조명</td>\n",
       "      <td>서부</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>장식품</td>\n",
       "      <td>북부</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>장식품</td>\n",
       "      <td>남부</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>장식품</td>\n",
       "      <td>동부</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>장식품</td>\n",
       "      <td>서부</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>장식품</td>\n",
       "      <td>북부</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>장식품</td>\n",
       "      <td>남부</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>장식품</td>\n",
       "      <td>동부</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>장식품</td>\n",
       "      <td>서부</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>장식품</td>\n",
       "      <td>북부</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>장식품</td>\n",
       "      <td>남부</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>장식품</td>\n",
       "      <td>동부</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>장식품</td>\n",
       "      <td>서부</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Decoration_Type Region  Sales\n",
       "0               트리     북부     64\n",
       "1               트리     남부     67\n",
       "2               트리     동부     84\n",
       "3               트리     서부     87\n",
       "4               트리     북부     87\n",
       "5               트리     남부     29\n",
       "6               트리     동부     41\n",
       "7               트리     서부     56\n",
       "8               트리     북부     90\n",
       "9               트리     남부     32\n",
       "10              트리     동부     78\n",
       "11              트리     서부     85\n",
       "12              조명     북부     59\n",
       "13              조명     남부     66\n",
       "14              조명     동부     57\n",
       "15              조명     서부     45\n",
       "16              조명     북부     97\n",
       "17              조명     남부     92\n",
       "18              조명     동부     29\n",
       "19              조명     서부     40\n",
       "20              조명     북부     89\n",
       "21              조명     남부     99\n",
       "22              조명     동부     67\n",
       "23              조명     서부     84\n",
       "24             장식품     북부     69\n",
       "25             장식품     남부     49\n",
       "26             장식품     동부     39\n",
       "27             장식품     서부     39\n",
       "28             장식품     북부     34\n",
       "29             장식품     남부     59\n",
       "30             장식품     동부     52\n",
       "31             장식품     서부     85\n",
       "32             장식품     북부     29\n",
       "33             장식품     남부     77\n",
       "34             장식품     동부     52\n",
       "35             장식품     서부     51"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"christmas_decoration_sales.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a0377f-9aa5-459e-9153-cf3843d34d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method interval in module scipy.stats._distn_infrastructure:\n",
      "\n",
      "interval(confidence, *args, **kwds) method of scipy.stats._continuous_distns.t_gen instance\n",
      "    Confidence interval with equal areas around the median.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    confidence : array_like of float\n",
      "        Probability that an rv will be drawn from the returned range.\n",
      "        Each value should be in the range [0, 1].\n",
      "    arg1, arg2, ... : array_like\n",
      "        The shape parameter(s) for the distribution (see docstring of the\n",
      "        instance object for more information).\n",
      "    loc : array_like, optional\n",
      "        location parameter, Default is 0.\n",
      "    scale : array_like, optional\n",
      "        scale parameter, Default is 1.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    a, b : ndarray of float\n",
      "        end-points of range that contain ``100 * alpha %`` of the rv's\n",
      "        possible values.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This is implemented as ``ppf([p_tail, 1-p_tail])``, where\n",
      "    ``ppf`` is the inverse cumulative distribution function and\n",
      "    ``p_tail = (1-confidence)/2``. Suppose ``[c, d]`` is the support of a\n",
      "    discrete distribution; then ``ppf([0, 1]) == (c-1, d)``. Therefore,\n",
      "    when ``confidence=1`` and the distribution is discrete, the left end\n",
      "    of the interval will be beyond the support of the distribution.\n",
      "    For discrete distributions, the interval will limit the probability\n",
      "    in each tail to be less than or equal to ``p_tail`` (usually\n",
      "    strictly less).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "help(scipy.stats.t.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18a8db-8381-4d03-b358-e2219b1a3767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
